# Logic Complexity Report - All Traced Tools

## Executive Summary

This document provides detailed logic complexity analysis for all 6 traced doc-manager tools, including complexity ratings, code structure metrics, maintainability assessment, and refactoring recommendations.

**Key Findings:**
- 2 tools rated "Very Complex" (5/10): validate_docs, assess_quality
- 1 tool rated "Complex" (4/10): detect_changes
- Average complexity: 3.5/10 - Moderate overall
- Main complexity drivers: Large files (500+ lines), hardcoded values, multiple responsibilities

**Complexity Rating Scale:**
- **1 (Trivial)** - Single responsibility, <50 lines, no nesting
- **2 (Simple)** - Clear flow, <200 lines, minimal nesting
- **3 (Moderate)** - Some complexity, <300 lines, 2-3 levels of nesting
- **4 (Complex)** - Multiple concerns, >400 lines, hardcoded logic
- **5 (Very Complex)** - Many responsibilities, >500 lines, needs refactoring

---

## Complexity Summary Table

| Tool | Rating | LOC | Functions | Nesting | Cyclomatic | Main Issues |
|------|--------|-----|-----------|---------|------------|-------------|
| **docmgr_init** | 2 (Simple) | 154 | 4 | 2 levels | ~8 | None - Clean orchestrator |
| **docmgr_update_baseline** | 3 (Moderate) | 284 | 6 | 3 levels | ~15 | Long function (109 lines) |
| **docmgr_detect_platform** | 2 (Simple) | 291 | 8 | 2 levels | ~12 | Repeated code patterns |
| **docmgr_detect_changes** | 4 (Complex) | 732 | 15+ | 3-4 levels | ~30 | Hardcoded paths + patterns |
| **docmgr_validate_docs** | 5 (Very Complex) | 573 | 13 | 3-4 levels | ~45 | 6 validators in one file |
| **docmgr_assess_quality** | 5 (Very Complex) | 771 | 10+ | 3-4 levels | ~40 | 7 analyzers + fuzzy logic |

**Average Complexity: 3.5/10** (Moderate)

---

## Detailed Analysis by Tool

### 1. docmgr_init
**Location:** `doc_manager_mcp/tools/state/init.py:22`
**Complexity Rating: 2/10 (Simple)**

#### Metrics
- **Lines of Code:** 154
- **Functions:** 4 (1 main + 3 helpers)
- **Max Nesting:** 2 levels
- **Cyclomatic Complexity:** ~8
- **Longest Function:** `docmgr_init()` - 45 lines

#### Structure
```
docmgr_init()                    [45 lines] - Main orchestrator
‚îú‚îÄ‚îÄ _create_config()             [30 lines] - Config file creation
‚îú‚îÄ‚îÄ _create_repo_baseline()      [25 lines] - File scanning
‚îú‚îÄ‚îÄ _create_memory_baseline()    [20 lines] - Symbol extraction
‚îî‚îÄ‚îÄ _create_dependencies()       [25 lines] - Mapping creation
```

#### Code Quality: 9/10
**Strengths:**
‚úÖ Clear separation of concerns
‚úÖ Single responsibility per function
‚úÖ Minimal nesting (max 2 levels)
‚úÖ Good error handling
‚úÖ Well-named functions

**Minor Issues:**
‚ö†Ô∏è Silent config overwrite (doesn't warn if .doc-manager.yml exists)

#### Example - Clean Orchestration Pattern
```python
# doc_manager_mcp/tools/state/init.py:22-66
def docmgr_init(...):
    """Clean orchestrator pattern - low complexity"""
    config_path = project_path / ".doc-manager.yml"

    # Step 1: Create config
    _create_config(config_path, sources, docs_path, platform, ...)

    # Step 2: Create baselines (3 independent operations)
    _create_repo_baseline(project_path, ...)
    _create_memory_baseline(project_path, ...)
    _create_dependencies(project_path, ...)

    return {"status": "success", ...}
```

**Why it's simple:**
- Linear flow, no complex branching
- Each helper does one thing
- No hardcoded values
- Easy to test and maintain

#### Recommendations: None needed - Already well-structured

---

### 2. docmgr_update_baseline
**Location:** `doc_manager_mcp/tools/state/update_baseline.py:10`
**Complexity Rating: 3/10 (Moderate)**

#### Metrics
- **Lines of Code:** 284
- **Functions:** 6 (1 main + 5 helpers)
- **Max Nesting:** 3 levels
- **Cyclomatic Complexity:** ~15
- **Longest Function:** `_update_repo_baseline()` - **109 lines** ‚ö†Ô∏è

#### Structure
```
update_baseline()                       [35 lines] - Orchestrator
‚îú‚îÄ‚îÄ _update_repo_baseline()             [109 lines] ‚ö†Ô∏è - File scanning + checksums
‚îú‚îÄ‚îÄ _update_symbol_baseline()           [55 lines] - TreeSitter parsing
‚îú‚îÄ‚îÄ _update_dependencies()              [45 lines] - Dependency mapping
‚îî‚îÄ‚îÄ Shared logic from dependency module [~40 lines reused]
```

#### Code Quality: 7/10
**Strengths:**
‚úÖ Reuses dependency tracking logic
‚úÖ Atomic baseline updates
‚úÖ Good error handling

**Issues:**
üî¥ `_update_repo_baseline()` too long (109 lines) - Should split into smaller functions
üî¥ **Missing file locking** - Race conditions possible (CRITICAL)
‚ö†Ô∏è Duplicate file scanning logic (also in init, detect_changes)

#### Example - Long Function Problem
```python
# doc_manager_mcp/tools/state/update_baseline.py:93-201
def _update_repo_baseline(project_path, sources, ...):
    """109 lines - TOO LONG"""

    # 1. Build exclude patterns (15 lines)
    exclude_patterns = []
    if use_gitignore:
        # ... gitignore logic ...
    exclude_patterns.extend(custom_patterns)

    # 2. Scan project files (30 lines)
    baseline = {"files": {}, "metadata": {...}}
    for root, dirs, files in os.walk(project_path):
        # ... complex filtering ...
        for file in files:
            # ... categorization logic ...
            baseline["files"][rel_path] = {...}

    # 3. Calculate checksums (20 lines)
    for file_path in baseline["files"]:
        # ... checksum calculation ...

    # 4. Write baseline (10 lines)
    # ... JSON serialization ...

    # 5. Return (5 lines)
    return baseline
```

**Why it's moderate complexity:**
- 5 distinct responsibilities in one function
- 3 levels of nesting (walk ‚Üí filter ‚Üí process)
- Could be 5 separate functions

#### Recommendations
**Priority: MEDIUM**
1. **Split `_update_repo_baseline()`** into 5 functions:
   ```python
   def _update_repo_baseline(...):
       exclude = _build_exclude_patterns(...)
       files = _scan_project_files(project_path, exclude)
       baseline = _categorize_files(files)
       _calculate_checksums(baseline)
       _write_baseline(baseline_path, baseline)
   ```
2. **Add file locking** (CRITICAL - see correctness issues)
3. **Extract shared scanning logic** to core/patterns.py

---

### 3. docmgr_detect_platform
**Location:** `doc_manager_mcp/tools/analysis/platform.py`
**Complexity Rating: 2/10 (Simple)**

#### Metrics
- **Lines of Code:** 291
- **Functions:** 8 (1 main + 7 helpers)
- **Max Nesting:** 2 levels
- **Cyclomatic Complexity:** ~12
- **Longest Function:** `docmgr_detect_platform()` - 40 lines

#### Structure
```
docmgr_detect_platform()                [40 lines] - 3-stage detection
‚îú‚îÄ‚îÄ _check_root_configs()               [35 lines] - Platform config files
‚îú‚îÄ‚îÄ _check_doc_directories()            [45 lines] - Doc-specific configs
‚îú‚îÄ‚îÄ _check_dependencies()               [30 lines] - package.json, requirements.txt
‚îî‚îÄ‚îÄ _recommend_platform()               [50 lines] - Recommendation logic
```

#### Code Quality: 8/10
**Strengths:**
‚úÖ Clean 3-stage detection flow
‚úÖ Well-separated concerns
‚úÖ Minimal nesting
‚úÖ O(1) complexity - Already optimal

**Minor Issues:**
‚ö†Ô∏è Repeated code in `_check_doc_directories()` - Similar checks for different platforms

#### Example - Repeated Pattern
```python
# doc_manager_mcp/tools/analysis/platform.py:~120-180
def _check_doc_directories(project_path: Path):
    """Repeated pattern for each platform"""

    # MkDocs check
    docs_dir = project_path / "docs"
    if docs_dir.exists():
        if (docs_dir / "mkdocs.yml").exists():
            return "mkdocs"

    # Sphinx check
    if docs_dir.exists():
        if (docs_dir / "conf.py").exists():
            return "sphinx"

    # Hugo check (similar pattern)
    if docs_dir.exists():
        if (docs_dir / "config.toml").exists():
            return "hugo"

    # ... 4 more similar checks
```

**Could be refactored to:**
```python
PLATFORM_MARKERS = {
    "mkdocs": ["mkdocs.yml", "mkdocs.yaml"],
    "sphinx": ["conf.py", "_build/"],
    "hugo": ["config.toml", "config.yaml"],
    # ...
}

def _check_doc_directories(project_path: Path):
    docs_dir = project_path / "docs"
    if not docs_dir.exists():
        return None

    for platform, markers in PLATFORM_MARKERS.items():
        if any((docs_dir / marker).exists() for marker in markers):
            return platform
```

#### Recommendations
**Priority: LOW**
1. **Extract platform markers** to configuration dict (1 hour)
2. **Reduce repeated checking** with data-driven approach (1 hour)

---

### 4. docmgr_detect_changes
**Location:** `doc_manager_mcp/tools/analysis/detect_changes.py` + `tools/_internal/changes.py`
**Complexity Rating: 4/10 (Complex)**

#### Metrics
- **Lines of Code:** 732 (203 main + 529 shared)
- **Functions:** 15+ (3 main + 12+ helpers)
- **Max Nesting:** 3-4 levels
- **Cyclomatic Complexity:** ~30
- **Longest Function:** `_map_to_affected_docs()` - 80 lines with **9 hardcoded paths** üî¥

#### Structure
```
docmgr_detect_changes()                 [85 lines] - Mode selection
‚îú‚îÄ‚îÄ _detect_changes_checksum()          [45 lines] - Checksum comparison
‚îú‚îÄ‚îÄ _detect_changes_git_diff()          [60 lines] - Git parsing
‚îî‚îÄ‚îÄ Shared logic (changes.py)           [529 lines]
    ‚îú‚îÄ‚îÄ _categorize_changed_file()      [120 lines] - 15+ hardcoded patterns
    ‚îú‚îÄ‚îÄ _map_to_affected_docs()         [80 lines] - **9 hardcoded doc paths** üî¥
    ‚îú‚îÄ‚îÄ _extract_semantic_changes()     [160 lines] - TreeSitter parsing
    ‚îî‚îÄ‚îÄ Helper functions                [~170 lines]
```

#### Code Quality: 6/10
**Strengths:**
‚úÖ Supports 2 modes (checksum + git diff)
‚úÖ Semantic analysis with TreeSitter
‚úÖ Categorization logic

**Critical Issues:**
üî¥ **Hardcoded file patterns** - 15+ patterns in `_categorize_changed_file()`
üî¥ **Hardcoded doc paths** - 9 paths in `_map_to_affected_docs()` (CRITICAL)
‚ö†Ô∏è Large shared module (529 lines) - Should be split

#### Example - Hardcoded Paths Problem
```python
# doc_manager_mcp/tools/_internal/changes.py:260-339
def _map_to_affected_docs(changed_files, category, project_path):
    """80 lines with 9 HARDCODED doc paths"""
    affected_docs = []

    if category == "cli":
        _add_affected_doc(
            affected_docs,
            "docs/reference/command-reference.md",  # HARDCODED ‚ùå
            f"CLI implementation changed: {file_path}",
            "high",
            file_path
        )

    elif category == "core":
        _add_affected_doc(
            affected_docs,
            "docs/architecture/core-architecture.md",  # HARDCODED ‚ùå
            ...
        )

    # ... 7 more hardcoded paths for different categories ...

    elif category == "dependencies":
        _add_affected_doc(
            affected_docs,
            "docs/reference/dependency-tracking.md",  # HARDCODED ‚ùå
            ...
        )
```

**Why this is a CRITICAL issue:**
- Fails for projects with non-standard doc layouts
- No way to configure paths per project
- Duplicate "docs/" prefix assumption
- Breaks if docs are in `documentation/`, `wiki/`, etc.

**Impact on complexity:**
- Adds 80 lines of repetitive code
- Makes function hard to test (needs specific file structure)
- Requires code changes for different projects

#### Recommendations
**Priority: CRITICAL**
1. **Make doc paths configurable** in .doc-manager.yml (4-6 hours):
   ```yaml
   # .doc-manager.yml
   doc_paths:
     cli: "docs/reference/command-reference.md"
     core: "docs/architecture/core-architecture.md"
     dependencies: "docs/reference/dependency-tracking.md"
     # ... configurable per project
   ```
2. **Extract categorization patterns** to patterns.py (2-3 hours)
3. **Split changes.py** into smaller modules (3-4 hours)

---

### 5. docmgr_validate_docs
**Location:** `doc_manager_mcp/tools/analysis/validation/validator.py`
**Complexity Rating: 5/10 (Very Complex)**

#### Metrics
- **Lines of Code:** 573 (LARGEST single-file tool)
- **Functions:** 13 (1 main + 6 validators + 6 helpers)
- **Max Nesting:** 3-4 levels
- **Cyclomatic Complexity:** ~45
- **Validation Types:** 6 (conventions, links, assets, snippets, syntax, symbols)
- **Issue Types Detected:** 20+

#### Structure
```
validate_docs()                         [90 lines] - Main orchestrator
‚îú‚îÄ‚îÄ _validate_conventions()             [48 lines] - Convention checking
‚îú‚îÄ‚îÄ _check_broken_links()               [41 lines] - Link resolution
‚îÇ   ‚îú‚îÄ‚îÄ _extract_links()                [25 lines] - Markdown + HTML parsing
‚îÇ   ‚îî‚îÄ‚îÄ _is_hugo_shortcode()            [10 lines] - Hugo detection
‚îú‚îÄ‚îÄ _validate_assets()                  [71 lines] - Image checking
‚îÇ   ‚îî‚îÄ‚îÄ _extract_images()               [30 lines] - Image extraction
‚îú‚îÄ‚îÄ _validate_code_snippets()           [52 lines] - Basic syntax
‚îÇ   ‚îî‚îÄ‚îÄ TreeSitter integration
‚îú‚îÄ‚îÄ _validate_code_syntax()             [29 lines] - Deep validation
‚îÇ   ‚îî‚îÄ‚îÄ CodeValidator integration
‚îî‚îÄ‚îÄ _validate_symbols()                 [40 lines] - Symbol verification
    ‚îî‚îÄ‚îÄ SymbolIndexer integration
```

#### Code Quality: 7/10
**Strengths:**
‚úÖ Comprehensive - 6 validation types
‚úÖ MarkdownParser integration
‚úÖ TreeSitter for accurate syntax checking
‚úÖ Hugo support (shortcodes, extensionless links)
‚úÖ Symlink safety (recursion protection)

**Issues:**
üî¥ **573 lines in single file** - Should extract validators to separate modules
üî¥ **Nested loops** - 3-4 levels deep in validation logic
‚ö†Ô∏è **Repeated markdown parsing** - Each validator re-parses files
‚ö†Ô∏è **No parallelization** - 6 validators run sequentially

#### Example - Nested Loop Complexity
```python
# doc_manager_mcp/tools/analysis/validation/validator.py:483-572
def validate_docs(docs_path, check_links=True, check_assets=True, ...):
    """90 lines - Orchestrates 6 validators"""
    issues = []

    # Find all markdown files
    md_files = find_markdown_files(docs_path)  # M files

    # Validator 1: Conventions
    if check_links:
        for file in md_files:                    # Loop 1: M iterations
            content = file.read_text()
            links = extract_links(content)
            for link in links:                    # Loop 2: L iterations
                # Check link validity
                for target in possible_targets:   # Loop 3: M iterations (WORST CASE)
                    if resolve_link(link, target):
                        break
                else:
                    issues.append(...)            # O(M√óL√óM) - QUADRATIC!

    # Validator 2: Assets (similar nesting)
    if check_assets:
        for file in md_files:                    # Loop 1
            images = extract_images(file)
            for image in images:                  # Loop 2
                # Check image exists

    # ... 4 more validators with similar nesting ...

    return issues
```

**Nesting levels:**
- Level 1: Markdown files loop (M)
- Level 2: Elements loop (links/images/blocks per file)
- Level 3: Validation checks per element
- Level 4: Sometimes nested conditionals within checks

#### Recommendations
**Priority: HIGH**
1. **Extract validators to separate modules** (3-4 hours):
   ```
   validation/
   ‚îú‚îÄ‚îÄ validator.py          [100 lines] - Main orchestrator
   ‚îú‚îÄ‚îÄ conventions.py        [80 lines] - Convention validator
   ‚îú‚îÄ‚îÄ links.py              [100 lines] - Link validator
   ‚îú‚îÄ‚îÄ assets.py             [100 lines] - Asset validator
   ‚îú‚îÄ‚îÄ snippets.py           [80 lines] - Snippet validator
   ‚îú‚îÄ‚îÄ syntax.py             [60 lines] - Syntax validator
   ‚îî‚îÄ‚îÄ symbols.py            [80 lines] - Symbol validator
   ```

2. **Build link index** to eliminate quadratic complexity (2-3 hours)
3. **Cache markdown parsing** (2-3 hours)
4. **Parallelize validators** with asyncio (2 hours)

---

### 6. docmgr_assess_quality
**Location:** `doc_manager_mcp/tools/analysis/quality/assessment.py`
**Complexity Rating: 5/10 (Very Complex)**

#### Metrics
- **Lines of Code:** 771 (2nd LARGEST tool)
- **Functions:** 10+ (1 main + 7 analyzers + helpers)
- **Max Nesting:** 3-4 levels
- **Cyclomatic Complexity:** ~40
- **Quality Criteria:** 7 (relevance, accuracy, purposefulness, uniqueness, consistency, clarity, structure)
- **Heuristics:** 15+ scoring rules

#### Structure
```
assess_quality()                        [120 lines] - Main orchestrator
‚îú‚îÄ‚îÄ analyze_relevance()                 [70 lines] - Check dates, deprecated refs
‚îú‚îÄ‚îÄ analyze_accuracy()                  [85 lines] - Compare with codebase
‚îú‚îÄ‚îÄ analyze_purposefulness()            [60 lines] - Check goals, audience
‚îú‚îÄ‚îÄ analyze_uniqueness()                [90 lines] - Detect duplication
‚îú‚îÄ‚îÄ analyze_consistency()               [95 lines] - Terminology, style
‚îú‚îÄ‚îÄ analyze_clarity()                   [80 lines] - Complexity metrics
‚îî‚îÄ‚îÄ analyze_structure()                 [75 lines] - Hierarchy, TOC
```

#### Code Quality: 7/10
**Strengths:**
‚úÖ Comprehensive - 7 quality dimensions
‚úÖ Quantitative scoring (good/fair/poor)
‚úÖ MarkdownParser integration
‚úÖ Clear criteria definitions

**Issues:**
üî¥ **771 lines in single file** - 2nd largest tool, needs modularization
‚ö†Ô∏è **Fuzzy heuristics** - Not deterministic, scoring can be inconsistent
‚ö†Ô∏è **Repeated parsing** - MarkdownParser called multiple times per file
‚ö†Ô∏è **No caching** - Re-processes same files across criteria

#### Example - Fuzzy Heuristic Logic
```python
# doc_manager_mcp/tools/analysis/quality/assessment.py:~300-350
def analyze_relevance(docs_path):
    """70 lines - Heuristic scoring"""
    findings = []

    for md_file in find_markdown_files(docs_path):
        content = md_file.read_text()

        # Heuristic 1: Check last updated (fuzzy)
        if "Last updated:" in content:
            date_str = extract_date(content)
            age_days = (datetime.now() - parse_date(date_str)).days

            if age_days > 365:                     # THRESHOLD: Arbitrary? ‚ö†Ô∏è
                findings.append("Possibly outdated (>1 year)")
            elif age_days > 180:                   # THRESHOLD: Why 180? ‚ö†Ô∏è
                findings.append("May need review (>6 months)")

        # Heuristic 2: Check for deprecated terms (fuzzy matching)
        deprecated_terms = ["deprecated", "obsolete", "legacy", "old"]
        for term in deprecated_terms:
            if term in content.lower():            # Simple string match ‚ö†Ô∏è
                findings.append(f"Contains '{term}' - verify relevance")

        # Heuristic 3: Cross-reference with codebase (expensive)
        apis_mentioned = extract_api_refs(content)
        for api in apis_mentioned:
            if not exists_in_codebase(api):        # Potentially slow ‚ö†Ô∏è
                findings.append(f"API {api} not found in codebase")

    # Score based on findings count (fuzzy thresholds)
    if len(findings) == 0:
        return {"score": "good", ...}
    elif len(findings) < 5:                        # THRESHOLD: Arbitrary? ‚ö†Ô∏è
        return {"score": "fair", ...}
    else:
        return {"score": "poor", ...}
```

**Why fuzzy logic increases complexity:**
- Arbitrary thresholds (365 days, 180 days, 5 findings)
- Simple string matching (misses context)
- Potentially expensive cross-referencing
- Non-deterministic results (thresholds may need tuning)

#### Recommendations
**Priority: MEDIUM**
1. **Extract analyzers to separate modules** (3-4 hours):
   ```
   quality/
   ‚îú‚îÄ‚îÄ assessment.py         [150 lines] - Main orchestrator
   ‚îú‚îÄ‚îÄ relevance.py          [100 lines] - Relevance analyzer
   ‚îú‚îÄ‚îÄ accuracy.py           [120 lines] - Accuracy analyzer
   ‚îú‚îÄ‚îÄ purposefulness.py     [90 lines] - Purposefulness analyzer
   ‚îú‚îÄ‚îÄ uniqueness.py         [120 lines] - Uniqueness analyzer
   ‚îú‚îÄ‚îÄ consistency.py        [130 lines] - Consistency analyzer
   ‚îú‚îÄ‚îÄ clarity.py            [110 lines] - Clarity analyzer
   ‚îî‚îÄ‚îÄ structure.py          [100 lines] - Structure analyzer
   ```

2. **Cache markdown parsing** (2-3 hours)
3. **Document heuristic thresholds** in configuration (1-2 hours):
   ```yaml
   # .doc-manager.yml or separate quality-config.yml
   quality_thresholds:
     relevance:
       max_age_days_warning: 180
       max_age_days_critical: 365
     consistency:
       min_term_similarity: 0.8
     # ... configurable thresholds
   ```

4. **Tune heuristics** based on feedback (ongoing)

---

## Cross-Tool Complexity Patterns

### Pattern 1: Simple Orchestrators (Complexity 2)
**Tools:** init, detect_platform

**Characteristics:**
- Linear flow, minimal branching
- Delegate to focused helper functions
- Each helper does one thing
- Easy to test and maintain

**Why they work well:**
```
Main function (30-50 lines):
  1. Validate inputs
  2. Call helper A (focused task)
  3. Call helper B (focused task)
  4. Call helper C (focused task)
  5. Aggregate results
  6. Return
```

**Lesson:** Keep orchestrators thin, push complexity to helpers

---

### Pattern 2: Moderate Complexity (Complexity 3)
**Tool:** update_baseline

**Characteristics:**
- Some long functions (100+ lines)
- 3 levels of nesting
- Mix of responsibilities in one function

**Why complexity increases:**
- Long functions with multiple steps
- Mixing I/O, logic, and data transformation
- Not splitting into smaller units

**Lesson:** Functions >50 lines should be split

---

### Pattern 3: High Complexity (Complexity 4)
**Tool:** detect_changes

**Characteristics:**
- Hardcoded values (patterns, paths)
- Large shared modules (500+ lines)
- Configuration embedded in code

**Why complexity increases:**
- Hardcoded values make code rigid
- No separation of config from logic
- Large modules mix concerns

**Lesson:** Extract configuration, split large modules

---

### Pattern 4: Very High Complexity (Complexity 5)
**Tools:** validate_docs, assess_quality

**Characteristics:**
- 500+ lines in single file
- Multiple responsibilities (6-7 validators/analyzers)
- Nested loops (3-4 levels)
- Fuzzy/heuristic logic

**Why complexity explodes:**
- Violation of Single Responsibility Principle
- All validators/analyzers in one file
- Repeated work (parsing, scanning)

**Lesson:** One validator/analyzer per file, max 100 lines each

---

## Refactoring Recommendations Summary

### HIGH Priority - Reduce Critical Complexity
1. **Make doc paths configurable** in detect_changes (4-6 hours)
   - Move 9 hardcoded paths to .doc-manager.yml
   - Impact: Fixes correctness + reduces complexity

2. **Modularize validate_docs** (3-4 hours)
   - Extract 6 validators to separate files
   - Impact: 573 lines ‚Üí 6 files of ~80-100 lines each

3. **Modularize assess_quality** (3-4 hours)
   - Extract 7 analyzers to separate files
   - Impact: 771 lines ‚Üí 7 files of ~90-120 lines each

**Total effort:** 10-14 hours
**Total impact:** Reduces complexity from 5‚Üí3 for largest tools

---

### MEDIUM Priority - Improve Maintainability
4. **Split `_update_repo_baseline()`** in update_baseline (2 hours)
   - 109 lines ‚Üí 5 functions of ~20 lines each

5. **Extract file scanning** to core/patterns.py (2-3 hours)
   - Removes duplication in 3 tools

6. **Extract exclude patterns** to core/patterns.py (1-2 hours)
   - Removes duplication in 3 tools

**Total effort:** 5-7 hours

---

### LOW Priority - Polish
7. **Extract platform markers** in detect_platform (1 hour)
   - Data-driven approach vs. repeated code

8. **Document heuristic thresholds** in assess_quality (1-2 hours)
   - Configuration for scoring rules

**Total effort:** 2-3 hours

---

## Code Quality Summary

| Tool | Current Quality | After Refactoring | Effort |
|------|-----------------|-------------------|--------|
| **docmgr_init** | 9/10 ‚úÖ | No change needed | 0 hours |
| **docmgr_update_baseline** | 7/10 | 8/10 | 2 hours |
| **docmgr_detect_platform** | 8/10 | 9/10 | 1 hour |
| **docmgr_detect_changes** | 6/10 ‚ö†Ô∏è | 8/10 | 6-9 hours |
| **docmgr_validate_docs** | 7/10 ‚ö†Ô∏è | 9/10 | 5-7 hours |
| **docmgr_assess_quality** | 7/10 ‚ö†Ô∏è | 8/10 | 5-6 hours |

**Current average: 7.3/10**
**After refactoring: 8.7/10**

**Total effort: 19-25 hours** for complete refactoring

---

## Related Documentation
- Individual tool complexity sections in `temp_mermaid/{tool}_arch/README.md`
- Performance analysis: `performance-comparison.md`
- Implementation plan: `optimization-roadmap.md`
